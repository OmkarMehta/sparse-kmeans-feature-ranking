{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q torch-scatter -f https://pytorch-geometric.com/whl/torch-1.10.0+cu111.html\n",
    "!pip install -q torch-sparse -f https://pytorch-geometric.com/whl/torch-1.10.0+cu111.html\n",
    "!pip install -q torch-geometric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "print(torch.version.cuda)\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import normalized_mutual_info_score as nmi, adjusted_rand_score as ari\n",
    "from sklearn.cluster import KMeans\n",
    "import random\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import tqdm\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.datasets import Planetoid, Reddit, Yelp\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SKFR1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implementing z score to normalize each feature using mean and std via torch\n",
    "def zscore(x):\n",
    "    '''\n",
    "    zscore normalization\n",
    "    '''\n",
    "    # get mean and std of each feature\n",
    "    mean = torch.mean(x)\n",
    "    std = torch.std(x)\n",
    "    # if std is not 0, then normalize each feature\n",
    "    if std != 0:\n",
    "        x = (x - mean) / std\n",
    "    else:\n",
    "        x = x - mean\n",
    "    return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch Implementation of the SKFR1 algorithm\n",
    "# Input: data of shape (features, samples), clusters, k (number of clusters), sparsity\n",
    "# Output: center of shape (features, clusters), clusters, list_loss\n",
    "def skfr1(data, clusters, k, sparsity, maxiter):\n",
    "    '''\n",
    "    SKFR1 algorithm\n",
    "    '''\n",
    "    # get number of features and samples\n",
    "    features, samples = data.shape\n",
    "    # criteria of shape (features)\n",
    "    criteria = torch.zeros(features).to(device)\n",
    "\n",
    "    # normalize each feature\n",
    "    for i in range(features):\n",
    "        data[i, :] = zscore(data[i, :])\n",
    "    \n",
    "    # list_loss empty list\n",
    "    list_loss = []\n",
    "    # number of iterations\n",
    "    num_iter = 1\n",
    "    switched = True\n",
    "\n",
    "    while switched and num_iter < maxiter:\n",
    "        # initialize clusters\n",
    "        center = torch.zeros(features, k).to(device)\n",
    "        # members of size clusters\n",
    "        members = torch.zero(k).to(device)\n",
    "        # for each sample\n",
    "        for j in range(samples):\n",
    "            # i as jth cluster \n",
    "            i = clusters[j]\n",
    "            # add sample to center\n",
    "            center[:, i] = center[:, i] + data[:, j]\n",
    "            # add 1 to members\n",
    "            members[i] = members[i] + 1\n",
    "        # for each cluster\n",
    "        for j in range(k):\n",
    "            # if members is not zero\n",
    "            if members[j] != 0:\n",
    "                # divide by members\n",
    "                center[:, j] = center[:, j] / members[j]\n",
    "        # update criteria d_l\n",
    "        criteria = torch.matmul(torch.mul(center, center), members.T)\n",
    "        # get index from criteria\n",
    "        index = torch.LongTensor([i for i in range(len(criteria))]).to(device)\n",
    "        # sort criteria\n",
    "        sorted_criteria = sorted(zip(criteria, index))\n",
    "        J = [x[1] for x in sorted_criteria]\n",
    "        # make long tensor of J\n",
    "        J = torch.LongTensor(J).to(device)\n",
    "        # get only features-sparsity features of J\n",
    "        J = J[:features-sparsity]\n",
    "        # for each J feature index\n",
    "        for i in range(len(J)):\n",
    "            center[J[i]] = torch.zeros(k).to(device)\n",
    "        # deleter members, criteria, index, sorted_criteria, J\n",
    "        del members, criteria, index, sorted_criteria, J\n",
    "\n",
    "        # get distamce as square root of sum of square of each feature \n",
    "        distance = torch.sqrt(((X.T - center.T[:, np.newaxis])**2).sum(axis=2))\n",
    "        switched = False\n",
    "        # for each sample\n",
    "        for i in range(samples):\n",
    "            # get index of minimum distance\n",
    "            j = torch.argmin(distance[:, i])\n",
    "            # if this index is not same as cluster\n",
    "            if clusters[i] != j:\n",
    "                # update cluster\n",
    "                clusters[i] = j\n",
    "                switched = True\n",
    "        # deleter distance\n",
    "        del distance\n",
    "        # WSS as sum of square of each feature. Initialize to zero\n",
    "        WSS = torch.zeros(k).to(device)\n",
    "        # for each cluster\n",
    "        for k in range(k):\n",
    "            # get temporary index where cluster is k\n",
    "            temp_index = torch.LongTensor(np.where(clusters.cpu().numpy() == k)[0]).to(device)\n",
    "            # tempX as zero tensor of shape (features, len(temp_index))\n",
    "            tempX = torch.zeros(features, len(temp_index)).to(device)\n",
    "            # for each temp_index\n",
    "            for j in range(len(temp_index)):\n",
    "                # add data to tempX\n",
    "                tempX[:, j] = data[:, temp_index[j]]\n",
    "            # get WSS\n",
    "            WSS[k] = torch.mean(((tempX.T - center[:, k]).T)**2)\n",
    "        # get loss as sum of WSS\n",
    "        loss = torch.sum(WSS)\n",
    "        # add loss to list_loss\n",
    "        list_loss.append(loss.item())\n",
    "        # print iteration number and loss\n",
    "        print('Iteration: {} Loss: {}'.format(num_iter, loss.item()))\n",
    "        # deleter tempX, temp_index, WSS, loss\n",
    "        del tempX, temp_index, WSS, loss\n",
    "        # update iteration number\n",
    "        num_iter += 1\n",
    "    return center, clusters, list_loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SKFR2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch Implementation of the SKFR2 algorithm\n",
    "# Input: data of shape (features, samples), clusters, k (number of clusters), sparsity\n",
    "# Output: center of shape (features, clusters), clusters, list_loss\n",
    "def skfr2(data, clusters, k, sparsity, maxiter):\n",
    "    '''\n",
    "    SKFR2 algorithm\n",
    "    '''\n",
    "    # get number of features and samples\n",
    "    features, samples = data.shape\n",
    "    # criteria of shape (features)\n",
    "    criteria = torch.zeros(features).to(device)\n",
    "\n",
    "    # normalize each feature\n",
    "    for i in range(features):\n",
    "        data[i, :] = zscore(data[i, :])\n",
    "    \n",
    "    # list_loss empty list\n",
    "    list_loss = []\n",
    "    # number of iterations\n",
    "    num_iter = 1\n",
    "    switched = True\n",
    "\n",
    "    while switched and num_iter < maxiter:\n",
    "        # initialize clusters\n",
    "        center = torch.zeros(features, k).to(device)\n",
    "        # members of size clusters\n",
    "        members = torch.zero(k).to(device)\n",
    "        # for each sample\n",
    "        for j in range(samples):\n",
    "            # i as jth cluster \n",
    "            i = clusters[j]\n",
    "            # add sample to center\n",
    "            center[:, i] = center[:, i] + data[:, j]\n",
    "            # add 1 to members\n",
    "            members[i] = members[i] + 1\n",
    "        # for each cluster\n",
    "        for j in range(k):\n",
    "            # if members is not zero\n",
    "            if members[j] > 0:\n",
    "                # divide by members\n",
    "                center[:, j] = center[:, j] / members[j]\n",
    "                # Get criteria = number of members in cluster multiplied by center*center\n",
    "                criteria = members[j] * torch.mul(center[:, j], center[:, j])\n",
    "                # get index from criteria\n",
    "                index = torch.LongTensor([i for i in range(len(criteria))]).to(device)\n",
    "                # sort criteria\n",
    "                sorted_criteria = sorted(zip(criteria, index))\n",
    "                J = [x[1] for x in sorted_criteria]\n",
    "                # make long tensor of J\n",
    "                J = torch.LongTensor(J).to(device)\n",
    "                # get only features-sparsity features of J\n",
    "                J = J[:features-sparsity]\n",
    "                for i in range(len(J)):\n",
    "                    center[J[i], j] = 0\n",
    "        # deleter members, criteria, index, sorted_criteria, J\n",
    "        del members, criteria, index, sorted_criteria, J\n",
    "\n",
    "        # get distamce as square root of sum of square of each feature \n",
    "        distance = torch.sqrt(((X.T - center.T[:, np.newaxis])**2).sum(axis=2))\n",
    "        switched = False\n",
    "        # for each sample\n",
    "        for i in range(samples):\n",
    "            # get index of minimum distance\n",
    "            j = torch.argmin(distance[:, i])\n",
    "            # if this index is not same as cluster\n",
    "            if clusters[i] != j:\n",
    "                # update cluster\n",
    "                clusters[i] = j\n",
    "                switched = True\n",
    "        # deleter distance\n",
    "        del distance\n",
    "        # WSS as sum of square of each feature. Initialize to zero\n",
    "        WSS = torch.zeros(k).to(device)\n",
    "        # for each cluster\n",
    "        for k in range(k):\n",
    "            # get temporary index where cluster is k\n",
    "            temp_index = torch.LongTensor(np.where(clusters.cpu().numpy() == k)[0]).to(device)\n",
    "            # tempX as zero tensor of shape (features, len(temp_index))\n",
    "            tempX = torch.zeros(features, len(temp_index)).to(device)\n",
    "            # for each temp_index\n",
    "            for j in range(len(temp_index)):\n",
    "                # add data to tempX\n",
    "                tempX[:, j] = data[:, temp_index[j]]\n",
    "            # get WSS\n",
    "            WSS[k] = torch.mean(((tempX.T - center[:, k]).T)**2)\n",
    "        # get loss as sum of WSS\n",
    "        loss = torch.sum(WSS)\n",
    "        # add loss to list_loss\n",
    "        list_loss.append(loss.item())\n",
    "        # print iteration number and loss\n",
    "        print('Iteration: {} Loss: {}'.format(num_iter, loss.item()))\n",
    "        # deleter tempX, temp_index, WSS, loss\n",
    "        del tempX, temp_index, WSS, loss\n",
    "        # update iteration number\n",
    "        num_iter += 1\n",
    "    return center, clusters, list_loss\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
